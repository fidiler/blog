---
title: Lecture 03 GFS 阅读笔记
author: "Soul Mate"
categories: ["MIT-6.824"]
date: 2019-04-20
url: "/distributed-systems/mit-6.824/lec03-gfs-notes.html"
---

## GFS 是什么?

GFS是一个分布式文件系统，GFS不需要特别昂贵的机器，GFS可以运行在大量的廉价设备上，具有较高的容错性和性能。

## GFS 设计

### 预期

能够针对组件失效进行监控、冗余恢复

系统存储一定量的大文件，文件的大小通常在数百MB上，上GB的也有。系统需要支持小文件（但不需要对小文件做专门的优化）。

系统必须高效明确的定义客户端并发的追加操作。

对于网络，高性能的稳定网络带宽远比低延迟重要。

### 架构

**整体**

一个 GFS 集群包含一个单独的 Master 节点 ，多台 Chunk 服务器，并且同时被多个客户端访问。以用户级别的进程运行在Linux系统上。

**chunk**

存储的文件被分割成固定大小的chunk。master会为chunk创建一个全球唯一的标识。 Chunk 服务器把 Chunk 以 Linux 文件的形式保存在本地硬盘 上，并且根据指定的 Chunk 标识和字节范围来读写块数据。出于可靠性的考虑，chunk会被复制到多个chunk服务器上 (GFS是三个)。

**master**

Master节点管理元数据，元数据包括

- 名字空间
- 访问控制信息
- 文件和 Chunk 的映射信息
- 当前 Chunk 的位置信息

Master节点还管理chunk的活动

- Chunk 租用管理 

- 孤儿 Chunk 的回收

- Chunk 在 Chunk 服务器之间的迁移。

Master使用心跳信息周期的和每个chunk服务器通讯，发送指令到chunk服务器并接收chunk服务器的状态信息。

**客户端**

GFS 客户端代码以库的形式被链接到客户程序里。客户端代码实现了 GFS 文件系统的 API 接口函数、应用程序与 Master 节点和 Chunk 服务器通讯、 以及对数据进行读写操作。 客户端和 Master 节点的通信只获取元数据， 所有的数据操作都是由客户端直接和 Chunk 服务器进行交互的。 我们不提供 POSIX 标准的 API 的功能，因此，GFS API 调用不需要深入到 Linux vnode 级别。 

### 单一Master节点

GFS使用单一Master节点简化了系统设计，单一的 Master 节点可以通过全局的信息定位Chunk 的位置以及进行复制决策。但是单一Master节点也容易成为瓶颈，必须减少对Master节点的读写。于是GFS并不直接从Master服务器获取数据，而只是获得文件名和索引，同时还会获得相应的Chunk标识和副本。客户端根据这些信息去Chunk服务器获得数据。客户端还会用文件名和 Chunk 索引作为 key 缓存这些信息。 

### Chunk尺寸

chunk尺寸的选择非常重要，GFS选择的是64MB (该尺寸远大于一般的block)。选择较大的尺寸有以下几个优点

- 减少了客户端对master节点通讯的需求（只需要一次和master节点的通信就可以获取chunk的位置信息）
- 客户端可以轻松缓存一个数TB的工作数据集
- 客户端能够对一个块进行多次操作，这样就可以通过与 Chunk 服务器保持较长时间的 TCP 连接来减少网络负载。 
- 较大的 Chunk 尺寸减少了 Master 节点需要保存的元数据的数量。这就允许我们把元数据全部放在内存中

### 元数据

元数据保存在内存中，所以master服务器操作元数据时会非常快，但保存在内存中也有一个潜在的问题，就是受限于 Master服务器所拥有的内存大小。但是在实际应用中，这并不是一个严重的问题。Master 服务器只需要不到 64 个字 节的元数据就能够管理一个 64MB 的 Chunk。

Master 服务器并不保存持久化保存哪个 Chunk 服务器存有指定 Chunk 的副本的信息。Master 只是在启动时轮询chunk服务器，并通过周期性的心跳监控chunk，master并不试图把chunk信息持久的保存，因为存在 Chunk 服务器加入集群、离开集群、更名、失效、以及重启的时候，这种方式更简单。

操作日志记录了关键元数据的变更历史记录，操作日志是元数据唯一的持久化存储记录，也作为判断同步操作顺序的逻辑时间基线。日志到一定的量会做一次checkpoint，在灾难恢复的时候master服务器会从磁盘上读取，checkpoint以B-树的形式的数据结构存储，可以直接映射到内存，显著提高恢复速度。

### 一致性模型

#### 影响一致性的操作

- 修改元数据
- 写数据
- 追加数据

#### 元数据一致性

元数据只有一份，不存在多副本一致性的问题，GFS内部对元数据的修改都进行了加锁。

#### 顺序写一个chunk



一致的**

所有客户端，无论从哪个副本读取，读到的数据都一样，那么我们认为文件 region 是“一致的” 

**已定义的**


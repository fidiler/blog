---
title: Lecture 01 Lab Implements
author: "Soul Mate"
categories: ["MIT-6.824"]
date: 2019-4-13
url: "/distributed-systems/mit-6.824/lec01-lab-implements.html"
---

# Part I: Map/Reduce input and output

第一部分要求我们补全两个函数 `doMap()` 和 `doReduce()` .

`doMap()` 通过调用定义的 map 函数生成一个 key/value pair 集合, 分区函数根据 key 值把数据写入到中间文件. 

`doReduce()`收集 `doMap()` 函数生成的中间文件并将其读入到内存中,  然后对数据进行排序将**相同的 key聚集在一起**, 调用定义的 reduce 函数, 并将 reduce 输出追加到对应的分区文件. 

了解了需求以及这两个函数的功能后, 我们开始动手补全 `doMap()` 和 `doReduce()` 函数, 函数中注释可以在我们不知道如何做的时候给予我们指引, 所以在做之前需要了解这两个函数内部的注释.

**doMap**

```go
func doMap(
	jobName string,    // the name of the MapReduce job
	mapTaskNumber int, // which map task this is
	inFile string,
	nReduce int, // the number of reduce task that will be run ("R" in the paper)
	mapF func(file string, contents string) []KeyValue,
) {
	//
	// You will need to write this function.
	// 你需要编写此函数
	//
	// The intermediate output of a map task is stored as multiple
	// files, one per destination reduce task. The file name includes
	// both the map task number and the reduce task number. Use the
	// filename generated by reduceName(jobName, mapTaskNumber, r) as
	// the intermediate file for reduce task r. Call ihash() (see below)
	// on each key, mod nReduce, to pick r for a key/value pair.
	//
	// map 任务的中间输出存储为多个文件, 文件名应该包含 map 任务号和 reduce 任务号.
	// 使用reduceName(jobName, mapTaskNumber, r) 函数为中间输出生成文件名. 每个 key
	// 调用 ihash() (见下文) mod nReduce,  去选择 r 作为键值对写入到中间文件
	//
	//
	// mapF() is the map function provided by the application. The first
	// argument should be the input file name, though the map function
	// typically ignores it. The second argument should be the entire
	// input file contents. mapF() returns a slice containing the
	// key/value pairs for  reduce; see common.go for the definition of
	// KeyValue.
	//
	// mapF() 是应用程序提供的函数. 第一个参数是输入文件名称, 虽然通常会忽略它.
	// 第二个参数是文件内容. mapF() 返回片用于 reduce 的包含key/value 的 slice.
	// 参阅 common.go 以了解 keyValue 的定义.
	//
	// Look at Go's ioutil and os packages for functions to read
	// and write files.
	//
	// 查看 Go 的 ioutil 和 os 包以获取读写文件的功能.
	//
	// Coming up with a scheme for how to format the key/value pairs on
	// disk can be tricky, especially when taking into account that both
	// keys and values could contain newlines, quotes, and any other
	// character you can think of.
	//
	// 提出一个如何格式化磁盘上 key/value 对的方案可能很棘手, 特别考虑到 key 和 value
	// 两者都可能包含换行符, 引号, 和其他你能想到的字符.
	//
	// One format often used for serializing data to a byte stream that the
	// other end can correctly reconstruct is JSON. You are not required to
	// use JSON, but as the output of the reduce tasks *must* be JSON,
	// familiarizing yourself with it here may prove useful. You can write
	// out a data structure as a JSON string to a file using the commented
	// code below. The corresponding decoding functions can be found in
	// common_reduce.go.
	//
	//
	//   enc := json.NewEncoder(file)
	//   for _, kv := ... {
	//     err := enc.Encode(&kv)
	//
	// Remember to close the file after you have written all the values!
	//

	// 读取文件内容
	contents, err := ioutil.ReadFile(inFile)
	if err != nil {
		panic(err)
	}

	// 通过预定义的 map 函数生成中间的 key/value pair
	kvs := mapF(inFile, string(contents))

	// 对每个 key 通过分区函数写入到不同的 r 文件
	for _, kv := range kvs {
		filename := reduceName(jobName, mapTask, ihash(kv.Key) % nReduce)

		w, err := os.OpenFile(filename, os.O_CREATE | os.O_APPEND | os.O_WRONLY, 0644)
		if err != nil {
			panic(err)
		}

		enc := json.NewEncoder(w)

		if err = enc.Encode(&kv); err != nil {
			panic(err)
		}

		if err = w.Close(); err != nil {
			panic(err)
		}
	}
}
```

**doReduce**

```go
func doReduce(
	jobName string,       // the name of the whole MapReduce job
	reduceTaskNumber int, // which reduce task this is
	outFile string,       // write the output here
	nMap int,             // the number of map tasks that were run ("M" in the paper)
	reduceF func(key string, values []string) string,
) {
	//
	// You will need to write this function.
	//
	// 你需要编写此函数
	//
	// You'll need to read one intermediate file from each map task;
	// reduceName(jobName, m, reduceTaskNumber) yields the file
	// name from map task m.
	//
	// 你需要从每个 map 任务中读取一个中间文件;
	// reduceName(jobName, m, reduceTaskNumber) 可以生成 map 任务 m 的文件名.
	//
	// Your doMap() encoded the key/value pairs in the intermediate
	// files, so you will need to decode them. If you used JSON, you can
	// read and decode by creating a decoder and repeatedly calling
	// .Decode(&kv) on it until it returns an error.
	//
	// doMap() 函数对中间文件 key/value 进行了编码, 因此你需要进行解码.
	//  如果使用json, 你可以创建解码器调用 .Decode(&kv) 重复解码和读取,
	//  直到返回错误
	//
	// You may find the first example in the golang sort package
	// documentation useful.
	//
	// 你可能会发现 golang sort 包文档中的第一个示例很有用
	//
	// reduceF() is the application's reduce function. You should
	// call it once per distinct key, with a slice of all the values
	// for that key. reduceF() returns the reduced value for that key.
	//
	//
	// You should write the reduce output as JSON encoded KeyValue
	// objects to the file named outFile. We require you to use JSON
	// because that is what the merger than combines the output
	// from all the reduce tasks expects. There is nothing special about
	// JSON -- it is just the marshalling format we chose to use. Your
	// output code will look something like this:
	//
	// enc := json.NewEncoder(file)
	// for key := ... {
	// 	enc.Encode(KeyValue{key, reduceF(...)})
	// }
	// file.Close()
	//

	// 使用 map 聚合具有相同 key 的 value.
	kvMap := make(map[string][]string)

	for i := 0; i < nMap; i++ {
		// 读取 doMap 生成的文件
		filename := reduceName(jobName, i, reduceTask)

		r, err := os.Open(filename)
		if err != nil {
			panic(err)
		}

		dec := json.NewDecoder(r)

		var kv KeyValue

		// 把中间文件的数据读入到内存
		// map 中使用了json 对 KeyValue 进行编码,
		// 因此这里使用 json 进行解码
		for {
			if err = dec.Decode(&kv); err != nil {
				if err == io.EOF {
					break
				}

				panic(err)
			}

			kvMap[kv.Key] = append(kvMap[kv.Key], kv.Value)
		}
	}

	// 对数据进行 reduce 操作并写入文件
	w, err := os.Create(outFile)
	if err != nil {
		panic(err)
	}

	enc := json.NewEncoder(w)

	for k, v := range kvMap {
		if err = enc.Encode(&KeyValue{k, reduceF(k, v)}); err != nil {
			panic(err)
		}
	}

	if err = w.Close(); err != nil {
		panic(err)
	}
}
```

# Part II: Single-worker word count

Part II 要求我们实现单词出现次数统计, 我们的任务是把 `wc.go` 中的 `mapF()` 和 `reduceF()` 补充完整.

`mapF()` 会获得文件的内容, 我们需要从文本字符串中提取出单词, 并返回一个 mapreduce.KeyValue 的slice

`reduceF()` 获得一个 key 和由该 key 聚集的 value 数组, 我们需要统计单词的数量, 并返回一个字符串, 字符串中包含单词数量值.

**mapF**

```go
func mapF(filename string, contents string) []mapreduce.KeyValue {
    // string.FieldsFunc 可以分割文本内容, 配合 unicode.IsLetter 从
    // 文本中提取出单词.
	words := strings.FieldsFunc(contents, func(r rune) bool {
		return !unicode.IsLetter(r)
	})

	var kvs = make([]mapreduce.KeyValue, 0, len(words))

	for _, word := range words {
		kvs = append(kvs, mapreduce.KeyValue{Key: word, Value: ""})
	}

	return kvs
}
```

**reduceF**

```go
func reduceF(key string, values []string) string {
    // 统计单词的数量并转换为string类型返回
	// Your code here (Part II).
	return strconv.Itoa(len(values))
}
```

# Part III: Distributing MapReduce tasks

Part III 要求我们实现一个分布式的MapReduce (使用RPC模拟). 主要工作是补全 `schedule.go` 中的 `schedule()` 函数实现.  

`schedule()` 函数会在两个阶段调用:  map 阶段 和 reduce 阶段. 

map 阶段会选择一个可用的 worker 将数据文件发送给worker, worker 会调用 doMap 将文件划分并生成中间文件.

reduce 阶段也会选择一个可用的 worker 调用 reduce 程序读取 map 阶段生成的中间文件进行 reduce 操作.

**在实现这部分需要注意的几个问题:**

- worker 的注册通过 registerChan 通知
- 每个 worker 一次只能执行一个任务, 如果超过一个任务, 会报错
- registerChan 是一个非缓冲通道, worker 处理完后需要放回
- 所有的 worker 处理完毕后 schedule 才能返回

**schedule 具体实现:**

```go
func schedule(jobName string, mapFiles []string, nReduce int, phase jobPhase, registerChan chan string) {
	var ntasks int
	var n_other int // number of inputs (for reduce) or outputs (for map)
	switch phase {
	case mapPhase:
		ntasks = len(mapFiles)
		n_other = nReduce
	case reducePhase:
		ntasks = nReduce
		n_other = len(mapFiles)
	}

	fmt.Printf("Schedule: %v %v tasks (%d I/Os)\n", ntasks, phase, n_other)

	// All ntasks tasks have to be scheduled on workers. Once all tasks
	// have completed successfully, schedule() should return.
	//
	// Your code here (Part III, Part IV).
	//

	wg := sync.WaitGroup{}

	wg.Add(ntasks)

	// 根据任务数量创建 worker 线程
	for taskNumber := 0; taskNumber < ntasks; taskNumber++ {
		arg := DoTaskArgs{
			JobName:       jobName,
			File:          mapFiles[taskNumber],
			Phase:         phase,
			TaskNumber:    taskNumber,
			NumOtherPhase: n_other,
		}

		go func() {
			// worker 可能在 schedule 运行前注册, 也可能在之后注册,
			// 因此需要不断询问是否有 worker 准备就绪
			for {

				// 从 worker 中获取地址, 通过 call 进行调用
				// worker 是一个非缓冲的通道, 因此一次只能有一个线程读取其中的数据,
				// 于是某个线程读取之后其他线程都会等待
				addr := <-registerChan

				call(addr, "Worker.DoTask", &arg, nil)

				// 因为其他线程在等待可用的 worker, 因此这里需要做一个通知的动作,
				// 也就是将用过的 addr 放回去
				go func() {registerChan<-addr}()

				break
			}

			wg.Done()
		}()
	}

	// 等待所有的 worker 执行完毕返回
	wg.Wait()

	fmt.Printf("Schedule: %v done\n", phase)
}
```

# Part IV: Handling worker failures

Part IV 部分要求我们处理 worker 失败,  主要工作是让 Part III 部分`schedule()` 能够容忍worker的失败.

因为map  和  reduce 都是函数式的, 不会保存状态, 因此 MapReduce 框架能够保证多次调用总能产生相同的输出, 并且输出的内容是完整的. 

因此 Part IV 部分的实现是非常简单的:

只需要当 worker 执行失败时重新将任务分配即可.

**Part IV schedule具体实现:**

```go
func schedule(jobName string, mapFiles []string, nReduce int, phase jobPhase, registerChan chan string) {
	var ntasks int
	var n_other int // number of inputs (for reduce) or outputs (for map)
	switch phase {
	case mapPhase:
		ntasks = len(mapFiles)
		n_other = nReduce
	case reducePhase:
		ntasks = nReduce
		n_other = len(mapFiles)
	}

	fmt.Printf("Schedule: %v %v tasks (%d I/Os)\n", ntasks, phase, n_other)

	// All ntasks tasks have to be scheduled on workers. Once all tasks
	// have completed successfully, schedule() should return.
	//
	// Your code here (Part III, Part IV).
	//

	wg := sync.WaitGroup{}

	wg.Add(ntasks)

	// 根据任务数量创建 worker 线程
	for taskNumber := 0; taskNumber < ntasks; taskNumber++ {
		arg := DoTaskArgs{
			JobName:       jobName,
			File:          mapFiles[taskNumber],
			Phase:         phase,
			TaskNumber:    taskNumber,
			NumOtherPhase: n_other,
		}

		go func() {
			// worker 可能在 schedule 运行前注册, 也可能在之后注册,
			// 因此需要不断询问是否有 worker 准备就绪
			for {

				// 从 worker 中获取地址, 通过 call 进行调用
				// worker 是一个非缓冲的通道, 因此一次只能有一个线程读取其中的数据,
				// 于是某个线程读取之后其他线程都会等待
				addr := <-registerChan

				// Part IV 部分: 只需要让 worker 重新执行即可
				if call(addr, "Worker.DoTask", &arg, nil) == true {
					// 因为其他线程在等待可用的 worker, 因此这里需要做一个通知的动作,
					// 也就是将用过的 addr 放回去
					go func() {registerChan<-addr}()

					break
				}
			}

			wg.Done()
		}()
	}

	// 等待所有的 worker 执行完毕返回
	wg.Wait()

	fmt.Printf("Schedule: %v done\n", phase)
}
```

在完成这部分代码后, 我想了解的是 worker 是如何失败的,  经过我查看代码后发现:

 课程提供了两个测试案例, 分别是 `TestOneFailure` 和 `TestManyFailures.`

先来看 `TestOneFailure`

```go
func TestOneFailure(t *testing.T) {
	mr := setup()
	// Start 2 workers that fail after 10 tasks
	go RunWorker(mr.address, port("worker"+strconv.Itoa(0)),
		MapFunc, ReduceFunc, 10, nil)
	go RunWorker(mr.address, port("worker"+strconv.Itoa(1)),
		MapFunc, ReduceFunc, -1, nil)
	mr.Wait()
	check(t, mr.files)
	checkWorker(t, mr.stats)
	cleanup(mr)
}
```



`RunWorker` 代码

```go
func RunWorker(MasterAddress string, me string,
	MapFunc func(string, string) []KeyValue,
	ReduceFunc func(string, []string) string,
	nRPC int, parallelism *Parallelism,
) {
	....
	
    wk.nRPC = nRPC
	
    ....

    for {
		wk.Lock()
        // 2. 递减到 0 就会close
		if wk.nRPC == 0 {
			wk.Unlock()
			break
		}
		wk.Unlock()
		conn, err := wk.l.Accept()
		if err == nil {
			wk.Lock()
			// 1. 每接收一次调用就会递减
            wk.nRPC--
			wk.Unlock()
			go rpcs.ServeConn(conn)
		} else {
			break
		}
	}
	wk.l.Close()
	debug("RunWorker %s exit\n", me)
}
```



从代码看到 worker-0 只能执行十个任务, 十个任务结束就会 close,  因为使用的 unix domain socket, 因此该文件会被删除,  当分配worker reduce 任务时, 就会造成失败.

再来看 `TestManyFailures`

```go
func TestManyFailures(t *testing.T) {
	mr := setup()
	i := 0
	done := false
	for !done {
		select {
		case done = <-mr.doneChannel:
			check(t, mr.files)
			cleanup(mr)
			break
		default:
			// Start 2 workers each sec. The workers fail after 10 tasks
			w := port("worker" + strconv.Itoa(i))
			go RunWorker(mr.address, w, MapFunc, ReduceFunc, 10, nil)
			i++
			w = port("worker" + strconv.Itoa(i))
			go RunWorker(mr.address, w, MapFunc, ReduceFunc, 10, nil)
			i++
			time.Sleep(1 * time.Second)
		}
	}
}
```

从代码中可以看出:  在任务没有结束时, 每秒都会新建 2 个 worker , 并且 worker 只能处理 10 次任务, 因此在程序运行过程中会有大量的 worker 失效和重建, 从而达到测试 worker 容错的目的.

# Part V: Inverted index generation (optional, does not count in grade)

Part V 部分是一个为文档生成反向索引的程序, 和 Part II 类似，我们需要在 `main/ii.go` 中实现 `mapF`和 `reduceF`

`mapF` 中我们需要从文件内容中切分出单词, 并将该单词和文件名映射起来

```go
func mapF(document string, value string) (res []mapreduce.KeyValue) {
	// Your code here (Part V).

	words := strings.FieldsFunc(value, func(r rune) bool {
		return !unicode.IsLetter(r)
	})

	res = make([]mapreduce.KeyValue, 0, len(words))

	for _, word := range words {
		res = append(res, mapreduce.KeyValue{Key: word, Value: document})
	}

	return
}
```

`reduceF` 需要统计出单词出现在多少个文件中以及对应的文件是什么，由于会有大量的重复文件名，因此需要去重处理

```go
func reduceF(key string, values []string) string {
	// Your code here (Part V).
	m := make(map[string]int)

	for _, value := range values {
		m[value] = 0
	}


	var newValues = make([]string, 0, len(m))

	for k := range m {
		newValues = append(newValues, k)
	}

	sort.Strings(newValues)

	return strconv.Itoa(len(newValues)) + " " + strings.Join(newValues, ",")
}
```

